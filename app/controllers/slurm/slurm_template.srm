#!/bin/bash
#SBATCH -J {experiment_name}   #Nome job
#SBATCH -p {instance_type}     #Fila (partition) a ser utilizada
#SBATCH --account={account}
#SBATCH --nodes=1               #Numero de Nós
#SBATCH --ntasks-per-node=1     #Numero de tarefas por Nó
#SBATCH --ntasks=1              #Numero de tarefas
#SBATCH --exclusive
#SBATCH --exclude atn1b01n16,atn1b01n08,atn1b03n25,atn1b01n19
#SBATCH -o {atena_root}/false_NFS/scripts/{task_id}/job_%j.txt

echo "CUDA_VISIBLE_DEVICES: " $CUDA_VISIBLE_DEVICES
echo $SLURM_JOB_NODELIST
echo "SLURM_JOBID: " $SLURM_JOBID
JOBNAME=$SLURM_JOB_NAME
echo "JOBNAME: " $JOBNAME

export HTTP_PROXY=http://ffir:L24v19l15!@inet-sys.petrobras.com.br:804
export HTTPS_PROXY=$HTTP_PROXY
export http_proxy=$HTTP_PROXY
export https proxy=$HTTP_PROXY
export https_proxy=$HTTP_PROXY

# Print proxy variables to verify they are set correctly
echo "HTTP_PROXY: $HTTP_PROXY"
echo "HTTPS_PROXY: $HTTPS_PROXY"

# Check MLflow version
singularity exec {sif_path}/teste_sif_mlflow_miniforge_py310_mlflow2_14.sif mlflow --version

# TODO: check if container.sif exists
singularity run --nv -B {atena_root} {sif_path}/{image_name}.sif python3 {atena_root}/false_NFS/scripts/{task_id}/{script_name} --input_path={atena_root}/datasets/{dataset_name} --output_path={atena_root}/false_NFS/scripts/{task_id}
